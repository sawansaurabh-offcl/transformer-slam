# transformer-slam
A hands-on 12-week Robotics and AI integration mini project | Pytorch -> LoFTR style matching -> CUDA

# Transformer-SLAM ğŸš€  
[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)  
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?logo=pytorch&logoColor=white)](https://pytorch.org/)  
[![CUDA](https://img.shields.io/badge/CUDA-Enabled-green.svg)](https://developer.nvidia.com/cuda-toolkit)  
[![License](https://img.shields.io/badge/license-MIT-lightgrey.svg)](LICENSE)  

> A 12-week structured roadmap to build a **Transformer-based SLAM pipeline** using PyTorch and CUDA â€” from perception to planning.

---

## ğŸ§© Overview
This repository provides a **modular, week-by-week learning plan** to go from PyTorch fundamentals to a fully working **Transformer-based SLAM** system.  
The end goal: **build, train, and extend** a Transformer model that performs both **visual SLAM** and **trajectory planning**.

### Highlights
- ğŸ”¥ End-to-end Transformer SLAM architecture  
- âš™ï¸ CUDA optimization & performance profiling  
- ğŸ§­ Decision Transformer / Diffusion Policy extension  
- ğŸ“Š Portfolio-ready results & documentation  

---

## ğŸ“ Repository Structure

```
Transformer-SLAM/
â”‚
â”œâ”€â”€ phase1_pytorch_basics/
â”‚   â”œâ”€â”€ train_vit_toy.py
â”‚   â””â”€â”€ attention_visualization.ipynb
â”‚
â”œâ”€â”€ phase2_feature_matching/
â”‚   â””â”€â”€ loftr_simplified.py
â”‚
â”œâ”€â”€ phase3_pose_estimation_cuda/
â”‚   â””â”€â”€ pose_from_correspondences.py
â”‚
â”œâ”€â”€ phase4_planning_extension/
â”‚   â””â”€â”€ transformer_planner.py
â”‚
â”œâ”€â”€ data/                     # KITTI / TUM-RGBD data (not included)
â”œâ”€â”€ outputs/                  # Logs, plots, and trained weights
â”œâ”€â”€ environment.yml           # Conda environment
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/Transformer-SLAM.git
cd Transformer-SLAM
```

### 2. Create a Conda environment
```bash
conda env create -f environment.yml
conda activate transformer_slam
```

### 3. Install extra dependencies
```bash
pip install torch torchvision kornia opencv-python matplotlib evo
```

### 4. Verify CUDA setup
```python
import torch
print(torch.cuda.is_available())
```

---

## ğŸ§  Learning Roadmap

### **Phase 1 â€“ PyTorch Foundations (Weeks 1â€“3)**
- Linear regression & CNNs from scratch  
- Custom Dataset & DataLoader  
- ViT (toy version) + attention visualization  

### **Phase 2 â€“ Transformer Feature Matching (Weeks 4â€“6)**
- LoFTR-style feature matching  
- KITTI/TUM-RGBD dataset training  
- Kornia feature matching + AMP training  

### **Phase 3 â€“ Pose Estimation & CUDA (Weeks 7â€“9)**
- Essential matrix estimation using OpenCV  
- GPU profiling with Nsight Systems  
- Custom CUDA kernel  

### **Phase 4 â€“ Planning Extension (Weeks 10â€“12)**
- Decision Transformer or Diffusion Planner  
- Sequence modeling on robot state data  
- Comparative visualization of results  

---

## ğŸ§° Tools & Dependencies

| Category | Tools |
|-----------|-------|
| **Deep Learning** | PyTorch, torchvision, Kornia |
| **CUDA & Profiling** | torch.profiler, Nsight Systems |
| **Vision & Geometry** | OpenCV, NumPy |
| **Datasets** | KITTI, TUM-RGBD |
| **Visualization** | Matplotlib, evo |
| **Environment** | Ubuntu + Conda (GPU RTX 3060+ recommended) |

---

## ğŸ“Š Deliverables
- âœ… Transformer-based SLAM model  
- âœ… CUDA kernel + profiling report  
- âœ… Planning module (Decision Transformer / Diffusion Policy)  
- âœ… Visualized SLAM & planning comparisons  

---

## ğŸ§­ References
- [PyTorch Tutorials](https://pytorch.org/tutorials/)  
- [LoFTR: Detector-Free Local Feature Matching](https://arxiv.org/abs/2104.00680)  
- [Decision Transformer](https://arxiv.org/abs/2106.01345)  
- [Diffusion Policy](https://github.com/real-stanford/diffusion_policy)  
- [OpenCV Pose Estimation Docs](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html)

---

## ğŸªª License
This project is licensed under the [MIT License](LICENSE).  
Feel free to fork, modify, and share it for educational or research purposes.

---

### ğŸ’¬ Author
**Sawan Saurabh** â€“ Robotics Software Engineer  
ğŸŒ [LinkedIn](https://linkedin.com/in/sawan-saurabh) | [GitHub](https://github.com/sawansaurabh-offcl)

---

> _"From pixels to plans â€” building the bridge between perception and decision."_  
